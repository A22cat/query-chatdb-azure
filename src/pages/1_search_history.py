# å±¥æ­´æ¤œç´¢
import streamlit as st
import os
from dotenv import load_dotenv
import openai
from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from azure.search.documents.models import VectorizedQuery
from azure.cosmos import CosmosClient


# --- UIãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---
st.set_page_config(page_title="ã‚¯ã‚¨ãƒªãƒãƒ£ãƒƒãƒˆDB Azure(Qnect)(ã‚­ãƒ¥ãƒã‚¯ãƒˆ)", page_icon="ğŸ”—", layout="wide")
st.title("ğŸ” å±¥æ­´æ¤œç´¢")
st.caption("ãƒãƒ£ãƒƒãƒˆã®å±¥æ­´ã‹ã‚‰ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨æ„å‘³ï¼ˆãƒ™ã‚¯ãƒˆãƒ«ï¼‰ã®ä¸¡æ–¹ã§é¡ä¼¼ã—ãŸã‚„ã‚Šå–ã‚Šã‚’æ¤œç´¢ã—ã¾ã™ã€‚")

# --- åˆæœŸè¨­å®šã¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®æº–å‚™ ---
load_dotenv()

# Streamlitã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ã‚’ä½¿ã£ã¦ã€ãƒªã‚½ãƒ¼ã‚¹ã‚’åŠ¹ç‡çš„ã«ç®¡ç†
@st.cache_resource
def get_openai_client():
    return openai.AzureOpenAI(
        api_key=os.getenv("AZURE_OPENAI_API_KEY"),
        api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
        azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
    )

@st.cache_resource
def get_search_client():
    endpoint = os.getenv("AZURE_SEARCH_ENDPOINT")
    key = os.getenv("AZURE_SEARCH_KEY")
    index_name = os.getenv("AZURE_SEARCH_INDEX_NAME", "chat-history-index")
    if endpoint and key:
        return SearchClient(endpoint=endpoint, index_name=index_name, credential=AzureKeyCredential(key))
    return None

@st.cache_resource
def get_cosmos_container():
    endpoint = os.getenv("AZURE_COSMOS_ENDPOINT")
    key = os.getenv("AZURE_COSMOS_KEY")
    db_name = os.getenv("AZURE_COSMOS_DATABASE")
    container_name = os.getenv("AZURE_COSMOS_CONTAINER")
    if not all([endpoint, key, db_name, container_name]):
        return None
    try:
        client = CosmosClient(endpoint, key)
        db = client.get_database_client(db_name)
        container = db.get_container_client(container_name)
        return container
    except Exception:
        return None

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
def generate_openai_embedding(text, client):
    if not text: return None
    try:
        response = client.embeddings.create(input=text, model=os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME"))
        return response.data[0].embedding
    except Exception as e:
        st.error(f"Embeddingç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

def search_ai_search(query_text, search_client, openai_client, top_n=3): #Azure AI Search (ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢)ã®çµæœä»¶æ•°n=Xã®ã¨ãXä»¶ã€‚3ä»¶è¡¨ç¤ºã€‚
    if not search_client or not query_text: return []
    try:
        embedding = generate_openai_embedding(query_text, openai_client)
        vector_queries = [VectorizedQuery(vector=embedding, k_nearest_neighbors=top_n, fields="summary_vector")] if embedding else None
        results = search_client.search(
            search_text=query_text,
            vector_queries=vector_queries,
            select=["id", "question", "summary", "timestamp"],
            top=top_n
        )
        return [result for result in results]
    except Exception as e:
        st.error(f"AI Search æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def search_cosmos_db(query_text, container):
    if not container or not query_text: return []
    try:
        query = "SELECT * FROM c WHERE CONTAINS(LOWER(c.question), @query) OR CONTAINS(LOWER(c.summary), @query) OR CONTAINS(LOWER(c.summary_chat), @query)"
        params = [{"name": "@query", "value": query_text.lower()}]
        items = list(container.query_items(query=query, parameters=params, enable_cross_partition_query=True))
        return items
    except Exception as e:
        st.error(f"Cosmos DBæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return []

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å–å¾—
openai_client = get_openai_client()
search_client = get_search_client()
cosmos_container = get_cosmos_container()

if not all([openai_client, search_client, cosmos_container]):
    st.warning("å¿…è¦ãªè¨­å®šï¼ˆAzure OpenAI, AI Search, Cosmos DBï¼‰ãŒç’°å¢ƒå¤‰æ•°ã«æ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
else:
    search_query = st.text_input("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", placeholder="ä¾‹ï¼šå¾“æ¥­å“¡ã®å£²ä¸Šã«ã¤ã„ã¦")
    if st.button("æ¤œç´¢å®Ÿè¡Œ", type="primary"):
        if search_query:
            with st.spinner("å±¥æ­´ã‚’æ¤œç´¢ä¸­..."):
                st.markdown("### Azure AI Search (ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢) ã®çµæœ")
                ai_search_results = search_ai_search(search_query, search_client, openai_client)
                if ai_search_results:
                    for result in ai_search_results:
                        with st.container(border=True):
                            st.markdown(f"**è³ªå•:** {result.get('question', 'N/A')}")
                            st.markdown(f"**è¦ç´„:** {result.get('summary', 'N/A')}")
                            score = result.get('@search.score')
                            st.caption(f"é–¢é€£ã‚¹ã‚³ã‚¢: {score:.4f} | ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {result.get('timestamp')}" if score else f"ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {result.get('timestamp')}")
                else:
                    st.info("Azure AI Search ã§ä¸€è‡´ã™ã‚‹å±¥æ­´ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

                st.divider()

                st.markdown("### Cosmos DB (ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢) ã®çµæœ")
                cosmos_results = search_cosmos_db(search_query, cosmos_container)
                if cosmos_results:
                    for item in cosmos_results[:3]: # [:3]æ¤œç´¢çµæœã¯æœ€å¤§3ä»¶ã€‚æœ€å¤§3ä»¶ã¾ã§ã®ãƒ«ãƒ¼ãƒ—ã€‚
                        with st.container(border=True):
                            st.markdown(f"**è³ªå•:** {item.get('question', 'N/A')}")
                            summary = item.get('summary_ui') or item.get('summary_chat')
                            if summary: st.markdown(f"**è¦ç´„:** {summary}")
                            if item.get('generated_sql'): st.code(item.get('generated_sql'), language='sql')
                            st.caption(f"ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {item.get('timestamp')}")
                else:
                    st.info("Cosmos DB ã§ä¸€è‡´ã™ã‚‹å±¥æ­´ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.warning("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")